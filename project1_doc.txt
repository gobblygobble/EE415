			+--------------------+
			|        EE 415      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jehyeon Bang <bangjh0430@kaist.ac.kr>
Jinha Chung <gobblygobble@kaist.ac.kr>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

None, other than gdb and vim usage documents searched on Google. (unrelated to Pintos)

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

@ timer.c / timer.h:
	static struct list sleep_list: global variable sleep_list for list of sleeping threads

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Instead of calling thread_yield (), we first set the time for the thread to wake up,
and then insert the thread to the sleeping element list.
Afterwards, we do thread_block () and then set interrupt levels to their original values
via intr_set_level (old_level).
By blocking the interrupts, we hope to achieve atomicity in the possibly critical section.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

Instead of yielding the thread, we block it, and add it to the sleeping list.
Thus, we do not busy wait.
~~~~~

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

??We block interrupts while possibly accessing, or even dealing with race conditions.
~~~~~
??????Mention semaphores & locks?

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

~~~~~

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

~~~~~

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

@ threads.c / threads.h:
	@ struct thread {
		struct list_elem sleepelem: list element for sleeping threads list
		int64_t wakeup_time: time for thread to wake up
		struct lock *waiting_lock: the lock that the thread waits for
		struct list lock_list: list of locks that ~~~~~
		struct thread *max_waiter: thread that has the max priority, 
			out of the ones that wait on the lock that this thread holds
		int donated_priority: the priority of thread when it is donated some
	}
	explicitly declared @ thread.h:
		int thread_get_priority_of (const struct thread *):
			returns priority of thread that is passed by parameter.
		bool compare_priority (const struct list_elem *,
					const struct list_elem *, void * UNUSED):
			compares priorities of the two list_elem*s
		bool need_yield (void):
			determines whether thread_current () needs to yield
	explicitly declared & defined in thread.c:
		static int get_priority_from)list_elem (const struct list_elem *a):
			returns priority of the thread* list_entry (a, struct thread, elem)

@ synch.c / synch.h:
	@ struct lock {
		struct thread *max_waiter: the thread with maximum priority,
			out of the ones that wait on this lock
		struct list_elem elem: needed to call list-related functions
	}
	explicitly declared @ synch.c:
		static bool compare_max_waiter (const struct list_elem *a,
						const struct list_elem *b,
						void *aux UNUSED):
			compares the values of max_waiters' priorities of the two locks,
			passed by parameters
		static void donation (const struct lock *lock):
			properly performs priority donations recursively,
			by comparing priorities values of threads.
		static void donation_rb (const struct lock *lock):
			rolls back the donated_priority to what it would have been.
			Also a recursive function
		static bool compare_priority_sema (const struct list_elem *a,
						   const struct list_elem *b,
						   void *aux UNUSED):
			compares the values of two semaphores' waiting threads' priorities.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

~~~~~

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

In next_thread_to_run (), we call list_sort to sort the list in increasing priority order,
and then pop the thread element with highest priority using list_pop_back ().

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

If a donation is supposed to take place, we first update the lock's holder's max_waiter,
and then call the function donation ().
Inside donation (), we check if the lock's holder thread is NULL to avoid errors.
(It is supposed to be NULL if the lock is not held. Thus, no donation should take place when so.)
If it is NULL, we instantly return, since no donation should take place.
Then, if the priority of the lock's holder thread is smaller than the priority of the
lock's holder thread's max_waiter thread, we update the lock's holder thread's donated_priority
to that of the higher priority.
(If it is not, then we should do nothing or just return. In our code, we have written nothing after
the "if () {}", so that the function will automatically exit.)
Afterwards, we perform donation () with the holder thread's waiting_lock.
(The condition for the next donation to happen is that the holder thread's waiting_lock is not NULL.
Because if it is NULL, there is no more donation to occur.)
Hence, with this recursive call, we keep going until there is no need to donate.
After returning from the first donation (), we perform sema_down (), and when sema_down () returns,
we set lock's holder thread to the current thread with thread_current ().
If lock's semaphore's waiting thread list is empty, we set lock's max_waiter to NULL, since there are no waiting threads.
We thene insert the lock into the current thread's lock_list, ordered, via list_insert_ordered ().
Lastly, we set the current thread's maximum waiter thread to point to the above lock_list's waiting thread with the maximum priority.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

~~~~~

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

During the function call and changing the thread_current ()'s priority, a timer interrupt
~~~~~

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We've thought of multiple designs, but concluded to use this one.
Knowing the which locks a thread holds, and which threads wait on a lock
helps to clear the code, given that we've handled them properly.
Also, recursive calls of donation () and donation_rb () helps us write more complex
and messier algorithms in a simpler way.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

@ 2 new files- fixed_point_calc.c / fixed_point_calc.h:
	typedef int fp_t: typedef- for 4-byte integers (same as normal int)
			  we used typedef to distinguish between what we see
			  as real integers, and fixed point numbers.
	fp_t convert_int_to_fp;
	int convert_fp_to_int_trunc (fp_t);
	int convert_fp_to_int_round (fp_t);
	fp_t add_fp_and_fp (fp_t, fp_t);
	fp_t subtract_fp_from_fp (fp_t, fp_t);
	fp_t add_fp_and_int (fp_t, int);
	fp_t subtract_int_from_fp (int, fp_t);
	fp_t multiply_fp_by_fp (fp_t, fp_t);
	fp_t multiply_fp_by_int (fp_t, int);
	fp_t divied_fp_by_fp (fp_t, fp_t);
	fp_t divide_fp_by_int (fp_t, int);
	    =======> These functions' names suggest their roles.
	static int f = 1 << 14 : in 17.14 format, f is 2^14.
@ thread.c / thread.h:
	fp_t load_avg: the system's load_avg. (extern fp_t load_avg in thread.h)
	void thread_update_priority (struct thread *t):
		Updates thread t's priority as required.
	void thread_update_recent_cpu (struct thread *t):
		Updates thread t's recent_cpu as required.
	void system_update_load_avg (void):
		Updates the system's load_avg value.
	void thread_increment_recent_cpu (void):
		Increments the current thread's recent_cpu value by 1.
	struct list* get_readylist (void):
		Helps us access the static list ready_list.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0     00  00  00  63  61  59      A
 4     01  00  00  62  61  59      A
 8     02  00  00  62  61  59      A
12     03  00  00  62  61  59      A
16     04  00  00  62  61  59      A
20     05  00  00  61  61  59      B
24     05  01  00  61  60  59      A
28     06  01  00  61  60  59      A
32     07  01  00  61  60  59      A
36     08  01  00  61  60  59      A

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

When two threads have the same priorities, it is ambiguous which one to
run first. The assignment wanted us to use round-robin algorithm, similar
to that of a queue (FIFO).
This way, with the assumption that enough time is given, none of the threads
will face starvation.
However, it is worth noting that C will still not run so many times before the
100-th tick(when other values start to update), due to its high niceness.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

~~~~~

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Our code does not work yet. We haven't had much chance to work on the
third part of the assignment, because of our obsession to get perfect score
on the first two parts.
~~~~~

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We used typedef to distinguish between what we consider as actual integers,
and what we consider as fixed point numbers.
It seems like typedef-ing int as fp_t to denote fixed point numbers make
our code more readable.
Also, we gave names for any arithmetic associated with fixed point numbers,
because the function names were made to be pretty straightforward, and it
also makes other parts of the codes that use the calculations more readable.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

It was our first time obtaining such a large chunk of a skeleton code.
It took a lot of time to understand what certain parts of the codes try to do.
It feels like dealing with console_locks is the hardest on the first and second
part of the assignment.
We did not get the chance to work a lot on the third project.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

Yes, it did. It was very hard, but helped us realize that we didn't know
so much about OS as we thought we had understood during the lectures.
We think it helps our coding skills improve a lot, along with debugging skills,
like using gdb.
However, after a certain time of debugging, and realizing it is usually
simple typos that take away most of our time in debugging, it made us 
feel a little helpless, because there's practically not so much we can do
besides being more careful in the future to prevent such things from
happening again.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

Not in particular.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

We think the TAs are doing a great job and really appreciate it.

>> Any other comments?
